@article{bakanaWildAReYOLOLightweightEfficient2024,
  title = {{{WildARe-YOLO}}: {{A}} Lightweight and Efficient Wild Animal Recognition Model},
  shorttitle = {{{WildARe-YOLO}}},
  author = {Bakana, Sibusiso Reuben and Zhang, Yongfei and Twala, Bhekisipho},
  date = {2024-05-01},
  journaltitle = {Ecological Informatics},
  shortjournal = {Ecological Informatics},
  volume = {80},
  pages = {102541},
  issn = {1574-9541},
  doi = {10.1016/j.ecoinf.2024.102541},
  url = {https://www.sciencedirect.com/science/article/pii/S1574954124000839},
  urldate = {2025-02-14},
  abstract = {For the protection of endangered species and successful wildlife population monitoring, wild animal recognition is essential. While deep learning models like YOLOv5 have shown promise in real-time object recognition, their practical applicability may be constrained by their high processing requirements. In this paper, we suggest a faster and lighter version of YOLOv5s for wild animal recognition. To lower computational costs for model parameters and floating-point operations (FLOPs) for the backbone, our suggested model includes Mobile Bottleneck Block modules and an improved StemBlock. We also use Focal-EIoU as a loss function to gauge the accuracy of the predicted bounding boxes during inference and employ a BiFPN-based neck. We tested our technique on three datasets, including Wild Animal Facing Extinction, Fishmarket, and MS COCO 2017. Additionally, our technique is compared with state-of-the-art deep learning models, and from the baseline model we recorded a 17.65\% increase in FPS, 28.55\% model parameters reduction, and 50.92\% in FLOPs reduction. Furthermore, our model has a faster model loading time, which is critical for deployment in remote areas. This enables real-time species recognition on basic hardware, aiding conservation efforts through rapid analysis. The model advances deep learning in ecology by balancing efficiency with performance.},
  keywords = {Deep learning,Efficient,Lightweight,Loss function,Wild animal recognition},
  file = {/home/meitu/Zotero/storage/G3A27R62/S1574954124000839.html}
}

@article{croftTooManyWild2020,
  title = {Too Many Wild Boar? {{Modelling}} Fertility Control and Culling to Reduce Wild Boar Numbers in Isolated Populations},
  shorttitle = {Too Many Wild Boar?},
  author = {Croft, Simon and Franzetti, Barbara and Gill, Robin and Massei, Giovanna},
  year = {2020年9月18日},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {15},
  number = {9},
  pages = {e0238429},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0238429},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0238429},
  urldate = {2025-02-14},
  abstract = {Wild boar and feral swine number and range are increasing worldwide in parallel with their impact on biodiversity and human activities. The ecological and economic impact of this species include spread of diseases, vehicle collisions, damage to crops, amenities and infrastructures and reduction in plant and animal abundance and richness. As traditional methods such as culling have not contained the growth and spread of wild boar and feral pigs, alternative methods such as fertility control are now advocated. We used empirical data on two isolated wild boar populations to model and compare the effects of different regimes of culling and fertility control on population trends. We built a Bayesian population model and applied it to explore the implications for population control of various management options combining culling and/or contraception. The results showed that, whilst fertility control on its own was not sufficient to achieve the target reduction in wild boar number, adding fertility control to culling was more effective than culling alone. In particular, using contraceptives on 40\% of the population to complement the culling of 60\% of the animals, halved the time to achieve our target reduction compared with culling only. We conclude that, assuming the effort of adding fertility control to culling was found to be cost-effective in terms of population reduction, these two methods should be used simultaneously if a rapid decrease in wild boar number is required for a closed population.},
  langid = {english},
  keywords = {Contraception,Contraceptives,Fecundity,Forests,Livestock,Population density,Population growth,Swine},
  file = {/home/meitu/Zotero/storage/FTITKWIY/Croft et al. - 2020 - Too many wild boar Modelling fertility control and culling to reduce wild boar numbers in isolated.pdf}
}

@article{delisleImperfectDetectionWildlife2023,
  title = {Imperfect Detection and Wildlife Density Estimation Using Aerial Surveys with Infrared and Visible Sensors},
  author = {Delisle, Zackary J. and McGovern, Patrick G. and Dillman, Brian G. and Swihart, Robert K.},
  date = {2023},
  journaltitle = {Remote Sensing in Ecology and Conservation},
  volume = {9},
  number = {2},
  pages = {222--234},
  issn = {2056-3485},
  doi = {10.1002/rse2.305},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rse2.305},
  urldate = {2025-02-14},
  abstract = {Aerial vehicles equipped with infrared thermal sensors facilitate quick density estimates of wildlife, but detection error can arise from the thermal sensor and viewer of the infrared video. We reviewed published research to determine how commonly these sources of error have been assessed in studies using infrared video from aerial platforms to sample wildlife. The number of annual articles pertaining to aerial sampling using infrared thermography has increased drastically since 2018, but past studies inconsistently assessed sources of imperfect detection. We illustrate the importance of accounting for some of these types of error in a case study on white-tailed deer Odocoileus virginianus in Indiana, USA, using a simple double-observer approach. In our case study, we found evidence of false negatives associated with the viewer of infrared video. Additionally, we found that concordance between the detections of two viewers increased when using a red-green-blue camera paired with the infrared thermal sensor, when altitude decreased and when more stringent criteria were used to classify thermal signatures as deer. We encourage future managers and ecologists recording infrared video from aerial platforms to use double-observer methods to account for viewer-induced false negatives when video is manually viewed by humans. We also recommend combining infrared video with red-green-blue video to reduce false positives, applying stringent verification standards to detections in infrared and red-green-blue video and collecting data at lower altitudes over snow when needed.},
  langid = {english},
  keywords = {Density estimation,detection error,drones,infrared video,Odocoileus virginianus,thermal sensor},
  file = {/home/meitu/Zotero/storage/WDQZWY3G/Delisle et al. - 2023 - Imperfect detection and wildlife density estimation using aerial surveys with infrared and visible s.pdf;/home/meitu/Zotero/storage/D96DK6UV/rse2.html}
}

@article{fengAdaptiveEmbeddingNetwork2022,
  title = {An {{Adaptive Embedding Network}} with {{Spatial Constraints}} for the {{Use}} of {{Few-Shot Learning}} in {{Endangered-Animal Detection}}},
  author = {Feng, Jiangfan and Li, Juncai},
  date = {2022-04},
  journaltitle = {ISPRS International Journal of Geo-Information},
  volume = {11},
  number = {4},
  pages = {256},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2220-9964},
  doi = {10.3390/ijgi11040256},
  url = {https://www.mdpi.com/2220-9964/11/4/256},
  urldate = {2025-02-14},
  abstract = {Image recording is now ubiquitous in the fields of endangered-animal conservation and GIS. However, endangered animals are rarely seen, and, thus, only a few samples of images of them are available. In particular, the study of endangered-animal detection has a vital spatial component. We propose an adaptive, few-shot learning approach to endangered-animal detection through data augmentation by applying constraints on the mixture of foreground and background images based on species distributions. First, the pre-trained, salient network U2-Net segments the foregrounds and backgrounds of images of endangered animals. Then, the pre-trained image completion network CR-Fill is used to repair the incomplete environment. Furthermore, our approach identifies a foreground–background mixture of different images to produce multiple new image examples, using the relation network to permit a more realistic mixture of foreground and background images. It does not require further supervision, and it is easy to embed into existing networks, which learn to compensate for the uncertainties and nonstationarities of few-shot learning. Our experimental results are in excellent agreement with theoretical predictions by different evaluation metrics, and they unveil the future potential of video surveillance to address endangered-animal detection in studies of their behavior and conservation.},
  issue = {4},
  langid = {english},
  keywords = {few-shot learning,GIS,spatial constraints,species distributions},
  file = {/home/meitu/Zotero/storage/TTJVKUFH/Feng and Li - 2022 - An Adaptive Embedding Network with Spatial Constraints for the Use of Few-Shot Learning in Endangere.pdf}
}

@article{masseiFertilityControlMitigate2014,
  title = {Fertility Control to Mitigate Human–Wildlife Conflicts: A Review},
  shorttitle = {Fertility Control to Mitigate Human–Wildlife Conflicts},
  author = {Massei, Giovanna and Cowan, Dave},
  date = {2014-05-19},
  journaltitle = {Wildlife Research},
  shortjournal = {Wildl. Res.},
  volume = {41},
  number = {1},
  pages = {1--21},
  publisher = {CSIRO PUBLISHING},
  issn = {1448-5494},
  doi = {10.1071/WR13141},
  url = {https://www.publish.csiro.au/wr/WR13141},
  urldate = {2025-02-14},
  abstract = {As human populations grow, conflicts with wildlife increase. Concurrently, concerns about the welfare, safety and environmental impacts of conventional lethal methods of wildlife management restrict the options available for conflict mitigation. In parallel, there is increasing interest in using fertility control to manage wildlife. The present review aimed at analysing trends in research on fertility control for wildlife, illustrating developments in fertility-control technologies and delivery methods of fertility-control agents, summarising the conclusions of empirical and theoretical studies of fertility control applied at the population level and offering criteria to guide decisions regarding the suitability of fertility control to mitigate human–wildlife conflicts. The review highlighted a growing interest in fertility control for wildlife, underpinned by increasing numbers of scientific studies. Most current practical applications of fertility control for wild mammals use injectable single-dose immunocontraceptive vaccines mainly aimed at sterilising females, although many of these vaccines are not yet commercially available. One oral avian contraceptive, nicarbazin, is commercially available in some countries. Potential new methods of remote contraceptive delivery include bacterial ghosts, virus-like particles and genetically modified transmissible and non-transmissible organisms, although none of these have yet progressed to field testing. In parallel, new species-specific delivery systems have been developed. The results of population-level studies of fertility control indicated that this approach may increase survival and affect social and spatial behaviour of treated animals, although the effects are species- and context-specific. The present studies suggested that a substantial initial effort is generally required to reduce population growth if fertility control is the sole wildlife management method. However, several empirical and field studies have demonstrated that fertility control, particularly of isolated populations, can be successfully used to limit population growth and reduce human–wildlife conflicts. In parallel, there is growing recognition of the possible synergy between fertility control and disease vaccination to optimise the maintenance of herd immunity in the management of wildlife diseases. The review provides a decision tree that can be used to determine whether fertility control should be employed to resolve specific human–wildlife conflicts. These criteria encompass public consultation, considerations about animal welfare and feasibility, evaluation of population responses, costs and sustainability.},
  langid = {english},
  file = {/home/meitu/Zotero/storage/XFZTWFDI/Massei and Cowan - 2014 - Fertility control to mitigate human–wildlife conflicts a review.pdf}
}

@article{quiros-fernandezHuntersServingEcosystem2017,
  title = {Hunters Serving the Ecosystem: The Contribution of Recreational Hunting to Wild Boar Population Control},
  shorttitle = {Hunters Serving the Ecosystem},
  author = {Quirós-Fernández, Francisco and Marcos, Jaime and Acevedo, Pelayo and Gortázar, Christian},
  date = {2017-05-30},
  journaltitle = {European Journal of Wildlife Research},
  shortjournal = {Eur J Wildl Res},
  volume = {63},
  number = {3},
  pages = {57},
  issn = {1439-0574},
  doi = {10.1007/s10344-017-1107-4},
  url = {https://doi.org/10.1007/s10344-017-1107-4},
  urldate = {2025-02-14},
  abstract = {The extractive nature of recreational hunting may provide a service to both the ecosystem and society, namely the control of problem species. We reviewed the annual wild boar hunting bag data from hunting sites in Asturias (Spain) from 2000/01 to 2013/14, paying particular attention to the evolution on hunting estates after ban periods. We hypothesized that the annual hunting bag after a hunting ban would be larger than that of the pre-ban period, and that this difference could provide an indication of hunters’ relative contribution to wild boar population regulation. The total hunting bag grew during the study period, from 3723 wild boar (0.39ind/km2) in the 2000/01 hunting year to 7593 in that of 2013/14 (0.79ind/km2)—a mean annual increase of 5.63\%. Low hunting quotas cannot be blamed for these growing trends, since no more than 50\% of the authorized animals are hunted. The growth of the mean annual pre-ban hunting bag on the estates on which hunting bans took place was 8.46\%. The hunting bag grew by 40.33\% immediately after the hunting ban ended—a growth rate seven times higher than that of the background hunting bag. This constitutes a proxy of the regulatory effect of hunters on wild boar population growth. Following the remarkable increase after the ban, the wild boar hunting bag attained values that were slightly lower than those of the pre-ban period, which indicates that hunters are able to reduce wild boar abundance. Hunting, therefore, provides an important service to both the ecosystem and society by contributing to regulating the growth of problem species such as the wild boar.},
  langid = {english},
  keywords = {Ecosystem service,Hunting,Population dynamics,Sus scrofa,Wild ungulates},
  file = {/home/meitu/Zotero/storage/A56NKL8J/Quirós-Fernández et al. - 2017 - Hunters serving the ecosystem the contribution of recreational hunting to wild boar population cont.pdf}
}

@online{royComputerVisionBasedObject2022,
  type = {SSRN Scholarly Paper},
  title = {A {{Computer Vision-Based Object Localization Model}} for {{Endangered Wildlife Detection}}},
  author = {Roy, Arunabha Mohan and Bhaduri, Jayabrata and Kumar, Teerath and Raj, Kislay},
  date = {2022-09-05},
  number = {4315295},
  eprint = {4315295},
  eprinttype = {Social Science Research Network},
  location = {Rochester, NY},
  doi = {10.2139/ssrn.4315295},
  url = {https://papers.ssrn.com/abstract=4315295},
  urldate = {2025-02-14},
  abstract = {Objective.  With climatic instability, various ecological disturbances, and human actions threaten the existence of various endangered wildlife species.  Therefore, up-to-date accurate, and detailed detection plays an important role in protecting biodiversity losses, conservation, and ecosystem management. Current state-of-the-art wildlife detection models, however, often lack superior feature extraction capability in complex environments, limits the development of accurate and reliable detection models.  Method. To this end, we present WilDect-YOLO, deep learning (DL)-based automated high-performance detection model for real-time endangered wildlife detection.  This model introduces a new residual block in the CSPDarknet53 backbone for strong and discriminating deep spatial features extraction and integrates DenseNet to improve preserving critical feature information. To enhance receptive field representation, preserve fine-grain localized information, and improve feature fusion, Spatial Pyramid Pooling (SPP) and modified Path Aggregation Network (PANet) have been implemented that provide superior detection under various challenging environments. Results. Evaluating the model performance in a custom endangered wildlife dataset considering high variability and complex backgrounds, WilDect-YOLO obtains a mean average precision (mAP) value of 96.89 \%, F1-score of 97.87 \%, and precision value of 97.18 \% at a detection rate of 59.20 FPS outperforming current state-of-the-art models. Significance.  The present research provides an effective and efficient detection model addressing the shortcoming of existing DL-based wildlife detection models by providing highly accurate species-level localized bounding box prediction. Current work constitutes a step towards a non-invasive, fully automated animal observation system in real-time in-field applications.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer vision,Deep Learning (DL),Endangered wildlife detection,Object Detection (OD),Wildlife Preservation,You Only Look Once (YOLOv4) algorithm},
  file = {/home/meitu/Zotero/storage/B46VJ68N/Roy et al. - 2022 - A Computer Vision-Based Object Localization Model for Endangered Wildlife Detection.pdf}
}

@article{royWilDectYOLOEfficientRobust2023a,
  title = {{{WilDect-YOLO}}: {{An}} Efficient and Robust Computer Vision-Based Accurate Object Localization Model for Automated Endangered Wildlife Detection},
  shorttitle = {{{WilDect-YOLO}}},
  author = {Roy, Arunabha M. and Bhaduri, Jayabrata and Kumar, Teerath and Raj, Kislay},
  date = {2023-07},
  journaltitle = {Ecological Informatics},
  shortjournal = {Ecological Informatics},
  volume = {75},
  pages = {101919},
  issn = {15749541},
  doi = {10.1016/j.ecoinf.2022.101919},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1574954122003697},
  urldate = {2025-02-14},
  abstract = {Objective. With climatic instability, various ecological disturbances, and human actions threaten the existence of various endangered wildlife species. Therefore, an up-to-date accurate and detailed detection process plays an important role in protecting biodiversity losses, conservation, and ecosystem management. Current state-of-theart wildlife detection models, however, often lack superior feature extraction capability in complex environments, limiting the development of accurate and reliable detection models. Method. To this end, we present WilDect-YOLO, a deep learning (DL)-based automated high-performance detection model for real-time endangered wildlife detection. In the model, we introduce a residual block in the CSPDarknet53 backbone for strong and discriminating deep spatial features extraction and integrate DenseNet blocks to improve in preserving critical feature information. To enhance receptive field representation, preserve fine-grain localized information, and improve feature fusion, a Spatial Pyramid Pooling (SPP) and modified Path Aggregation Network (PANet) have been implemented that results in superior detection under various challenging environments. Results. Evaluating the model performance in a custom endangered wildlife dataset considering high variability and complex backgrounds, WilDect-YOLO obtains a mean average precision (mAP) value of 96.89\%, F1-score of 97.87\%, and precision value of 97.18\% at a detection rate of 59.20 FPS outperforming current state-of-the-art models. Significance. The present research provides an effective and efficient detection framework addressing the shortcoming of existing DL-based wildlife detection models by providing highly accurate species-level localized bounding box prediction. Current work constitutes a step toward a non-invasive, fully automated animal observation system in real-time in-field applications.},
  langid = {english},
  file = {/home/meitu/Zotero/storage/7DSVXB8R/Roy et al. - 2023 - WilDect-YOLO An efficient and robust computer vision-based accurate object localization model for a.pdf}
}

@inproceedings{vargheseYOLOv8NovelObject2024,
  title = {{{YOLOv8}}: {{A Novel Object Detection Algorithm}} with {{Enhanced Performance}} and {{Robustness}}},
  shorttitle = {{{YOLOv8}}},
  booktitle = {2024 {{International Conference}} on {{Advances}} in {{Data Engineering}} and {{Intelligent Computing Systems}} ({{ADICS}})},
  author = {Varghese, Rejin and M., Sambath},
  date = {2024-04},
  pages = {1--6},
  doi = {10.1109/ADICS58448.2024.10533619},
  url = {https://ieeexplore.ieee.org/document/10533619},
  urldate = {2025-02-14},
  abstract = {In recent years, the You Only Look Once (YOLO) series of object detection algorithms have garnered significant attention for their speed and accuracy in real-time applications. This paper presents YOLOv8, a novel object detection algorithm that builds upon the advancements of previous iterations, aiming to further enhance performance and robustness. Inspired by the evolution of YOLO architectures from YOLOv1 to YOLOv7, as well as insights from comparative analyses of models like YOLOv5 and YOLOv6, YOLOv8 incorporates key innovations to achieve optimal speed and accuracy. Leveraging attention mechanisms and dynamic convolution, YOLOv8 introduces improvements specifically tailored for small object detection, addressing challenges highlighted in YOLOv7. Additionally, the integration of voice recognition techniques enhances the algorithm's capabilities for video-based object detection, as demonstrated in YOLOv7. The proposed algorithm undergoes rigorous evaluation against state-of-the-art benchmarks, showcasing superior performance in terms of both detection accuracy and computational efficiency. Experimental results on various datasets confirm the effectiveness of YOLOv8 across diverse scenarios, further validating its suitability for real-world applications. This paper contributes to the ongoing advancements in object detection research by presenting YOLOv8 as a versatile and high-performing algorithm, poised to address the evolving needs of computer vision systems.},
  eventtitle = {2024 {{International Conference}} on {{Advances}} in {{Data Engineering}} and {{Intelligent Computing Systems}} ({{ADICS}})},
  keywords = {Benchmark testing,Computational Efficiency,Computer vision,Computer Vision Systems,Heuristic algorithms,Object Detection,Performance Enhancement,Performance evaluation,Robustness,Speech recognition,Technological innovation,YOLO,YOLOv8},
  file = {/home/meitu/Zotero/storage/YSQI2HS8/10533619.html}
}

@online{yaseenWhatYOLOv8InDepth2024,
  title = {What Is {{YOLOv8}}: {{An In-Depth Exploration}} of the {{Internal Features}} of the {{Next-Generation Object Detector}}},
  shorttitle = {What Is {{YOLOv8}}},
  author = {Yaseen, Muhammad},
  date = {2024-08-28},
  eprint = {2408.15857},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2408.15857},
  url = {http://arxiv.org/abs/2408.15857},
  urldate = {2025-02-14},
  abstract = {This study presents a detailed analysis of the YOLOv8 object detection model, focusing on its architecture, training techniques, and performance improvements over previous iterations like YOLOv5. Key innovations, including the CSPNet backbone for enhanced feature extraction, the FPN+PAN neck for superior multi-scale object detection, and the transition to an anchor-free approach, are thoroughly examined. The paper reviews YOLOv8's performance across benchmarks like Microsoft COCO and Roboflow 100, highlighting its high accuracy and real-time capabilities across diverse hardware platforms. Additionally, the study explores YOLOv8's developer-friendly enhancements, such as its unified Python package and CLI, which streamline model training and deployment. Overall, this research positions YOLOv8 as a state-of-the-art solution in the evolving object detection field.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/meitu/Zotero/storage/DXVTLF4S/Yaseen - 2024 - What is YOLOv8 An In-Depth Exploration of the Internal Features of the Next-Generation Object Detec.pdf;/home/meitu/Zotero/storage/AY8GBA8K/2408.html}
}
